{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise set 3\n",
    "## Answered to all questions (1-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "$$\n",
    "S_{W} = C_{0} + C_{1} \n",
    "= \\begin{pmatrix} 3 & 0 \\\\ 0 & 1\\end{pmatrix} + \\begin{pmatrix} 3 & -1 \\\\ -1 & 1\\end{pmatrix}\n",
    "= \\begin{pmatrix} 6 & -1 \\\\ -1 & 2\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_{W}^{-1} = \\frac{1}{6*2 - 1} \\begin{pmatrix} 6 & -1 \\\\ -1 & 2\\end{pmatrix}\n",
    "= \\begin{pmatrix} \\frac{2}{11} & \\frac{1}{11} \\\\ \\frac{1}{11} & \\frac{6}{11}\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Since the scale of projection vector $\\bf w$ dosen't matter, we can write\n",
    "\n",
    "$$\n",
    "{\\bf w} = S_{W}^{-1}(\\bf\\mu_{1} - \\bf\\mu_{0})\n",
    "= \\begin{pmatrix} 6 & -1 \\\\ -1 & 2\\end{pmatrix}\n",
    "(\\begin{pmatrix} 1 \\\\ 2\\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1\\end{pmatrix})\n",
    "=\\begin{pmatrix} 1 \\\\ 6\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "When classification problem is defined as a likelihood ratio test, I got following tresholds for $x$ (Derivation of tresholds is omitted, since it is long and messy):\n",
    "Classify projected sample $x$ in class 1 if\n",
    "\n",
    "$$\n",
    "c - \\sqrt{\\frac{2log(\\sigma_{1}\\sigma_{2}^{-1}) - \\sigma_{2}^{-2}\\mu_{2}^{2} - \\sigma_{1}^{-2}\\mu_{1}^{2} + \\frac{(\\sigma_{2}^{-2}\\mu_{2} - \\sigma_{1}^{-2}\\mu_{1})^{2}}{\\sigma_{2}^{-2}-\\sigma_{1}^{-2}}}\n",
    "{\\sigma_{2}^{-2} - \\sigma_{1}^{-2}}}\n",
    "<\n",
    "x\n",
    "<\n",
    "c + \\sqrt{\\frac{2log(\\sigma_{1}\\sigma_{2}^{-1}) - \\sigma_{2}^{-2}\\mu_{2}^{2} - \\sigma_{1}^{-2}\\mu_{1}^{2}+ \\frac{(\\sigma_{2}^{-2}\\mu_{2} - \\sigma_{1}^{-2}\\mu_{1})^{2}}{\\sigma_{2}^{-2}-\\sigma_{1}^{-2}}}\n",
    "{\\sigma_{2}^{-2} - \\sigma_{1}^{-2}}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "c = \\frac{\\sigma_{2}^{-2}\\mu_{2} - \\sigma_{1}^{-2}\\mu_{1}}{\\sigma_{2}^{-2} - \\sigma_{1}^{-2}} \\\\\n",
    "$$\n",
    "$$\n",
    "\\mu_{1} = \\bf w^{T} \\pmb{\\mu}_{0} \\\\\n",
    "$$\n",
    "$$\n",
    "\\sigma_{1}^{2} = \\bf w^{T} C_{0} \\bf w \\\\\n",
    "$$\n",
    "$$\n",
    "\\mu_{2} = \\bf w^{T} \\pmb{\\mu}_{1} \\\\\n",
    "$$\n",
    "$$\n",
    "\\sigma_{2}^{2} = \\bf w^{T} C_{1} \\bf w \n",
    "$$\n",
    "In the context of Question 1, numeric values of these parameters are:\n",
    "$$\n",
    "\\mu_{1} = \\bf{w^{T}} \\pmb{\\mu}_{0} = 7\\\\\n",
    "$$\n",
    "$$\n",
    "\\sigma_{1}^{2} = \\bf w^{T} C_{0} \\bf w = 39\\\\\n",
    "$$\n",
    "$$\n",
    "\\mu_{2} = \\bf w^{T} \\pmb{\\mu}_{1} = 13 \\\\\n",
    "$$\n",
    "$$\n",
    "\\sigma_{2}^{2} = \\bf{ w^{T}} C_{1} \\bf{w} = 27 \n",
    "$$\n",
    "By applying these to the formula given above, obtained tresholds are:\n",
    "$$\n",
    "9.30937 < x < 43.6906\n",
    "$$\n",
    "By using the $\\bf w$ derived in Q1, projected $x$ is:\n",
    "$$\n",
    "x = \\begin{pmatrix} 1 & 6\\end{pmatrix}\\begin{pmatrix} 1 \\\\ 2\\end{pmatrix} = 13\n",
    "$$\n",
    "Therefore, the point $\\bf x$ is classified to class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000/*.jpg\n",
      "00001/*.jpg\n",
      "00002/*.jpg\n",
      "00003/*.jpg\n",
      "00004/*.jpg\n",
      "00005/*.jpg\n",
      "00006/*.jpg\n",
      "00007/*.jpg\n",
      "00008/*.jpg\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import time\n",
    "import numpy as np\n",
    "from skimage.io import imread_collection\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "root = '/home/tuomas/Python/DATA.ML.200/Ex3/'\n",
    "images = []\n",
    "labels = []\n",
    "for i in range(0,9):\n",
    "    fn = '0000{}/*.jpg'.format(i)\n",
    "    print(fn)\n",
    "    imgs = imread_collection(root + fn)\n",
    "    images.append(np.array(imgs, dtype='object'))\n",
    "    labels.append( np.ones(len(imgs)) * i )\n",
    "\n",
    "#images = np.array(images, dtype='object')\n",
    "images = np.concatenate(images)\n",
    "labels = np.concatenate(labels).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images\n",
    "imgs_processed = []\n",
    "scaler = MinMaxScaler()\n",
    "for img in images:\n",
    "    # Resize & vectorize the image\n",
    "    img = cv2.resize(img, (32,32)).ravel()\n",
    "    # Scale sample to (0,1)\n",
    "    # Since MinMaxScaler scales data featurewise, I transposed the row vector into column vector\n",
    "    # so the samplewise scaling is performed\n",
    "    img_T = img[...,None]\n",
    "    scaler.fit(img_T)\n",
    "    img_T = scaler.transform(img_T)\n",
    "    \n",
    "    imgs_processed.append(img_T.ravel())\n",
    "    \n",
    "imgs_processed = np.array(imgs_processed).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets\n",
    "trainX, testX, trainY, testY = train_test_split(imgs_processed, \n",
    "                                                labels, \n",
    "                                                test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeighborsClassifier ...\n",
      "Testing KNeighborsClassifier ...\n",
      "Evaluating KNeighborsClassifier ...\n",
      "Training LinearDiscriminantAnalysis ...\n",
      "Testing LinearDiscriminantAnalysis ...\n",
      "Evaluating LinearDiscriminantAnalysis ...\n",
      "Training LogisticRegression ...\n",
      "Testing LogisticRegression ...\n",
      "Evaluating LogisticRegression ...\n",
      "Training SVC ...\n",
      "Testing SVC ...\n",
      "Evaluating SVC ...\n",
      "Training SVC ...\n",
      "Testing SVC ...\n",
      "Evaluating SVC ...\n",
      "Training RandomForestClassifier ...\n",
      "Testing RandomForestClassifier ...\n",
      "Evaluating RandomForestClassifier ...\n"
     ]
    }
   ],
   "source": [
    "# Train, test & evaluate given models \n",
    "models = [KNeighborsClassifier(n_neighbors=3),\n",
    "          LinearDiscriminantAnalysis(solver='svd'),\n",
    "          LogisticRegression(max_iter=10000),\n",
    "          SVC(kernel='linear'),\n",
    "          SVC(kernel='rbf'),\n",
    "          RandomForestClassifier(n_estimators=20)\n",
    "          ]\n",
    "\n",
    "accuracy = []\n",
    "tr_time = []\n",
    "tst_time = []\n",
    "for model in models:\n",
    "    # Training\n",
    "    print('Training {} ...'.format(model.__class__.__name__))\n",
    "    start = time.time()\n",
    "    model.fit(trainX, trainY)\n",
    "    tr_time.append( time.time() - start )\n",
    "    # Testing\n",
    "    print('Testing {} ...'.format(model.__class__.__name__))\n",
    "    start = time.time()\n",
    "    predY = model.predict(testX)\n",
    "    tst_time.append( time.time() - start )\n",
    "    # Evaluating\n",
    "    print('Evaluating {} ...'.format(model.__class__.__name__))\n",
    "    accuracy.append( accuracy_score(testY, predY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size (batch) = 6237\n",
      "Test set size = 2673\n",
      "\n",
      "Results for 3-NN\n",
      "----------------------\n",
      "Accuracy is 88.78 %\n",
      "Training time / batch 1.65 s\n",
      "Test time / sample 18.116 ms\n",
      "\n",
      "Results for LDA\n",
      "----------------------\n",
      "Accuracy is 80.96 %\n",
      "Training time / batch 11.56 s\n",
      "Test time / sample 0.006 ms\n",
      "\n",
      "Results for LogReg\n",
      "----------------------\n",
      "Accuracy is 94.28 %\n",
      "Training time / batch 32.31 s\n",
      "Test time / sample 0.006 ms\n",
      "\n",
      "Results for SVM linear\n",
      "----------------------\n",
      "Accuracy is 95.06 %\n",
      "Training time / batch 32.63 s\n",
      "Test time / sample 5.539 ms\n",
      "\n",
      "Results for SVM rbf\n",
      "----------------------\n",
      "Accuracy is 91.99 %\n",
      "Training time / batch 70.33 s\n",
      "Test time / sample 11.673 ms\n",
      "\n",
      "Results for Random forest\n",
      "----------------------\n",
      "Accuracy is 91.81 %\n",
      "Training time / batch 3.52 s\n",
      "Test time / sample 0.007 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the statistics\n",
    "model_names = ['3-NN','LDA','LogReg','SVM linear','SVM rbf','Random forest']\n",
    "print('Training set size (batch) = {}'.format(trainX.shape[0]))\n",
    "print('Test set size = {}\\n'.format(testX.shape[0]))\n",
    "for i in range(6):\n",
    "    print('Results for {}'.format(model_names[i]))\n",
    "    print('----------------------')\n",
    "    print('Accuracy is {} %'.format(round(accuracy[i]*100, 2)))\n",
    "    print('Training time / batch {} s'.format(round(tr_time[i], 2)))\n",
    "    print('Test time / sample {} ms\\n'.format(round(tst_time[i]*1000/testX.shape[0], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "By previous question, it seems that SVM linear had the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  51.5s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   51.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  51.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  51.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  51.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  51.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train and test set from previous exercise\n",
    "from sklearn.model_selection import cross_val_score\n",
    "trainX2 = np.concatenate((trainX, testX))\n",
    "trainY2 = np.concatenate((trainY, testY))\n",
    "model = SVC(kernel='linear')\n",
    "cv_scores = cross_val_score(model, trainX2, trainY2, cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of accuracies = 0.9584736251402919\n",
      "Standard deviation of accuracies = 0.0015470312853075455\n"
     ]
    }
   ],
   "source": [
    "print('Mean of accuracies = {}'.format(np.mean(cv_scores)))\n",
    "print('Standard deviation of accuracies = {}'.format(np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all images to 32 x 32\n",
    "images_resized = []\n",
    "for img in images:\n",
    "    images_resized.append(cv2.resize(img, (32,32)))\n",
    "\n",
    "images_resized = np.array(images_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing sets.\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "trainX, testX, trainY, testY = train_test_split(images_resized, \n",
    "                                                labels, \n",
    "                                                test_size=0.15)\n",
    "\n",
    "# One-hot encoding\n",
    "trainY = to_categorical(trainY, num_classes=9)\n",
    "testY_cat = to_categorical(testY, num_classes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 5, 5, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 4617      \n",
      "=================================================================\n",
      "Total params: 331,145\n",
      "Trainable params: 330,313\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,BatchNormalization,Dropout,Flatten,Dense\n",
    "\n",
    "layers=[Conv2D(filters=32, kernel_size = 3, activation='relu', input_shape = (32,32,3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=32, kernel_size = 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Conv2D(64, kernel_size = 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, kernel_size = 3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Conv2D(128, kernel_size = 4, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dropout(0.4),\n",
    "        Dense(9, activation='softmax')]\n",
    "\n",
    "cnn_model = Sequential(layers)\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "119/119 [==============================] - 6s 48ms/step - loss: 1.4053 - accuracy: 0.5504\n",
      "Epoch 2/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.3055 - accuracy: 0.8946\n",
      "Epoch 3/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.1569 - accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0982 - accuracy: 0.9663\n",
      "Epoch 5/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0723 - accuracy: 0.9781\n",
      "Epoch 6/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0595 - accuracy: 0.9795\n",
      "Epoch 7/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0536 - accuracy: 0.9814\n",
      "Epoch 8/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0438 - accuracy: 0.9852\n",
      "Epoch 9/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0302 - accuracy: 0.9901\n",
      "Epoch 10/10\n",
      "119/119 [==============================] - 1s 10ms/step - loss: 0.0314 - accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fea1484cf10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "cnn_model.fit(trainX, trainY, epochs=10, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 - 2s - loss: 0.0337 - accuracy: 0.9933\n",
      "Accuracy of CNN = 0.9932684898376465\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = cnn_model.evaluate(testX, testY_cat, verbose=2)\n",
    "print(\"Accuracy of CNN = {}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
